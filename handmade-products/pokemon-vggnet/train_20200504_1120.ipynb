{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, activation='relu', input_shape=inputShape))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 5e-4\n",
    "BS = 32\n",
    "IMAGE_DIMS = (200, 200, 3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print('[INFO] loading images...')\n",
    "imagePaths = sorted(list(paths.list_images('dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 2382.19MB\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)\n",
    "print('[INFO] data matrix: {:.2f}MB'.format(data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                        shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From <ipython-input-7-fcee58ef8064>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate on 509 samples\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 77s 1s/step - loss: 1.8030 - accuracy: 0.5055 - val_loss: 3.0204 - val_accuracy: 0.1532\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 1.2401 - accuracy: 0.6215 - val_loss: 2.1745 - val_accuracy: 0.2240\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 1.1597 - accuracy: 0.6455 - val_loss: 3.5789 - val_accuracy: 0.2554\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 1.0231 - accuracy: 0.6745 - val_loss: 6.6010 - val_accuracy: 0.2004\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 1.0306 - accuracy: 0.6840 - val_loss: 2.2411 - val_accuracy: 0.3399\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.9785 - accuracy: 0.6915 - val_loss: 3.3696 - val_accuracy: 0.4283\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.9210 - accuracy: 0.7065 - val_loss: 2.1661 - val_accuracy: 0.4538\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.8299 - accuracy: 0.7230 - val_loss: 1.2477 - val_accuracy: 0.6346\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.7699 - accuracy: 0.7325 - val_loss: 1.0892 - val_accuracy: 0.6483\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.7040 - accuracy: 0.7660 - val_loss: 1.4779 - val_accuracy: 0.6955\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.6974 - accuracy: 0.7690 - val_loss: 0.8781 - val_accuracy: 0.7250\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.6376 - accuracy: 0.7830 - val_loss: 1.4473 - val_accuracy: 0.6090\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.5898 - accuracy: 0.7895 - val_loss: 0.7592 - val_accuracy: 0.8016\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.6476 - accuracy: 0.7830 - val_loss: 0.8370 - val_accuracy: 0.7682\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.5819 - accuracy: 0.8110 - val_loss: 0.8900 - val_accuracy: 0.7583\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.5040 - accuracy: 0.8185 - val_loss: 1.0384 - val_accuracy: 0.7053\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.5124 - accuracy: 0.8195 - val_loss: 0.6199 - val_accuracy: 0.8035\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 13s 201ms/step - loss: 0.4632 - accuracy: 0.8300 - val_loss: 0.9788 - val_accuracy: 0.7367\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 13s 202ms/step - loss: 0.5456 - accuracy: 0.8225 - val_loss: 0.7172 - val_accuracy: 0.7819\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.4684 - accuracy: 0.8395 - val_loss: 0.6075 - val_accuracy: 0.8271\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.3872 - accuracy: 0.8620 - val_loss: 1.0170 - val_accuracy: 0.7387\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.3900 - accuracy: 0.8640 - val_loss: 0.6947 - val_accuracy: 0.8016\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.3807 - accuracy: 0.8685 - val_loss: 0.6566 - val_accuracy: 0.8114\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.3217 - accuracy: 0.8885 - val_loss: 0.7967 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.3166 - accuracy: 0.8845 - val_loss: 0.6579 - val_accuracy: 0.8232\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.3864 - accuracy: 0.8655 - val_loss: 0.6902 - val_accuracy: 0.8212\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.3391 - accuracy: 0.8810 - val_loss: 0.7173 - val_accuracy: 0.7996\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.2813 - accuracy: 0.9040 - val_loss: 0.7063 - val_accuracy: 0.7957\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 12s 198ms/step - loss: 0.2752 - accuracy: 0.9050 - val_loss: 0.6901 - val_accuracy: 0.8251\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.2761 - accuracy: 0.9060 - val_loss: 0.7163 - val_accuracy: 0.7996\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.3020 - accuracy: 0.8890 - val_loss: 0.7739 - val_accuracy: 0.8153\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.2210 - accuracy: 0.9240 - val_loss: 0.9670 - val_accuracy: 0.7741\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.2218 - accuracy: 0.9175 - val_loss: 1.6710 - val_accuracy: 0.6896\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.2333 - accuracy: 0.9150 - val_loss: 0.5722 - val_accuracy: 0.8585\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.2500 - accuracy: 0.9100 - val_loss: 0.6962 - val_accuracy: 0.7996\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.2504 - accuracy: 0.9175 - val_loss: 1.4925 - val_accuracy: 0.6876\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.3248 - accuracy: 0.8960 - val_loss: 0.6735 - val_accuracy: 0.8369\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.2151 - accuracy: 0.9245 - val_loss: 0.5721 - val_accuracy: 0.8448\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1992 - accuracy: 0.9265 - val_loss: 0.6030 - val_accuracy: 0.8507\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.2335 - accuracy: 0.9195 - val_loss: 0.7174 - val_accuracy: 0.8193\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.1962 - accuracy: 0.9285 - val_loss: 0.6032 - val_accuracy: 0.8507\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1796 - accuracy: 0.9350 - val_loss: 0.7199 - val_accuracy: 0.8114\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.1676 - accuracy: 0.9430 - val_loss: 0.5593 - val_accuracy: 0.8684\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.1497 - accuracy: 0.9510 - val_loss: 0.6084 - val_accuracy: 0.8527\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1270 - accuracy: 0.9525 - val_loss: 0.6649 - val_accuracy: 0.8527\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1890 - accuracy: 0.9355 - val_loss: 1.6286 - val_accuracy: 0.7073\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.2791 - accuracy: 0.9045 - val_loss: 0.6720 - val_accuracy: 0.8251\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1989 - accuracy: 0.9340 - val_loss: 0.6424 - val_accuracy: 0.8487\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.1695 - accuracy: 0.9370 - val_loss: 0.6539 - val_accuracy: 0.8389\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1573 - accuracy: 0.9460 - val_loss: 0.8273 - val_accuracy: 0.8193\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 12s 198ms/step - loss: 0.1327 - accuracy: 0.9510 - val_loss: 0.7029 - val_accuracy: 0.8310\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1227 - accuracy: 0.9535 - val_loss: 0.8641 - val_accuracy: 0.8173\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.1097 - accuracy: 0.9590 - val_loss: 0.7411 - val_accuracy: 0.8448\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 12s 198ms/step - loss: 0.1333 - accuracy: 0.9560 - val_loss: 0.7808 - val_accuracy: 0.8271\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1393 - accuracy: 0.9525 - val_loss: 0.6666 - val_accuracy: 0.8507\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 13s 199ms/step - loss: 0.1274 - accuracy: 0.9595 - val_loss: 0.6288 - val_accuracy: 0.8585\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 12s 198ms/step - loss: 0.1029 - accuracy: 0.9663 - val_loss: 0.5873 - val_accuracy: 0.8585\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1012 - accuracy: 0.9675 - val_loss: 0.8442 - val_accuracy: 0.8251\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.0938 - accuracy: 0.9710 - val_loss: 0.6628 - val_accuracy: 0.8566\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1117 - accuracy: 0.9615 - val_loss: 0.5527 - val_accuracy: 0.8605\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.1046 - accuracy: 0.9615 - val_loss: 0.7272 - val_accuracy: 0.8409\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1163 - accuracy: 0.9615 - val_loss: 0.6185 - val_accuracy: 0.8664\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.1107 - accuracy: 0.9615 - val_loss: 0.8795 - val_accuracy: 0.8271\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.1036 - accuracy: 0.9590 - val_loss: 0.7596 - val_accuracy: 0.8369\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.1067 - accuracy: 0.9675 - val_loss: 0.7724 - val_accuracy: 0.8271\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.1236 - accuracy: 0.9570 - val_loss: 0.7439 - val_accuracy: 0.8310\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.1112 - accuracy: 0.9645 - val_loss: 0.7517 - val_accuracy: 0.8369\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.0974 - accuracy: 0.9650 - val_loss: 1.1962 - val_accuracy: 0.7859\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.7334 - val_accuracy: 0.8468\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0979 - accuracy: 0.9650 - val_loss: 0.8168 - val_accuracy: 0.8428\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0871 - accuracy: 0.9680 - val_loss: 0.6116 - val_accuracy: 0.8644\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0940 - accuracy: 0.9655 - val_loss: 0.7878 - val_accuracy: 0.8527\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1093 - accuracy: 0.9620 - val_loss: 0.8065 - val_accuracy: 0.8350\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0959 - accuracy: 0.9655 - val_loss: 0.8096 - val_accuracy: 0.8330\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1005 - accuracy: 0.9625 - val_loss: 0.7293 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0888 - accuracy: 0.9635 - val_loss: 0.7133 - val_accuracy: 0.8566\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0900 - accuracy: 0.9695 - val_loss: 0.6860 - val_accuracy: 0.8468\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0756 - accuracy: 0.9720 - val_loss: 0.7708 - val_accuracy: 0.8468\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.5921 - val_accuracy: 0.8782\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0775 - accuracy: 0.9765 - val_loss: 0.7366 - val_accuracy: 0.8350\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0638 - accuracy: 0.9720 - val_loss: 0.7574 - val_accuracy: 0.8566\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0646 - accuracy: 0.9765 - val_loss: 0.8207 - val_accuracy: 0.8566\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0763 - accuracy: 0.9755 - val_loss: 0.7495 - val_accuracy: 0.8271\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0601 - accuracy: 0.9755 - val_loss: 0.8798 - val_accuracy: 0.8251\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0736 - accuracy: 0.9695 - val_loss: 0.7919 - val_accuracy: 0.8468\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 0.7638 - val_accuracy: 0.8585\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0525 - accuracy: 0.9800 - val_loss: 0.8377 - val_accuracy: 0.8487\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.7702 - val_accuracy: 0.8507\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0789 - accuracy: 0.9745 - val_loss: 0.7886 - val_accuracy: 0.8625\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0685 - accuracy: 0.9760 - val_loss: 0.6493 - val_accuracy: 0.8703\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 0.6610 - val_accuracy: 0.8625\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0543 - accuracy: 0.9840 - val_loss: 0.7088 - val_accuracy: 0.8527\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0854 - accuracy: 0.9685 - val_loss: 1.0112 - val_accuracy: 0.7701\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.1695 - accuracy: 0.9470 - val_loss: 0.8694 - val_accuracy: 0.8330\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.1023 - accuracy: 0.9625 - val_loss: 0.7708 - val_accuracy: 0.8507\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.1039 - accuracy: 0.9655 - val_loss: 0.8761 - val_accuracy: 0.8468\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0697 - accuracy: 0.9715 - val_loss: 0.9139 - val_accuracy: 0.8350\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.7145 - val_accuracy: 0.8644\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0498 - accuracy: 0.9860 - val_loss: 0.6736 - val_accuracy: 0.8821\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 12s 195ms/step - loss: 0.0782 - accuracy: 0.9755 - val_loss: 1.3691 - val_accuracy: 0.7819\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] compiling model...')\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print('[INFO] training network...')\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_20200504_1120.h5')\n",
    "\n",
    "f = open('label.pickle', 'wb')\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, N), H.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, N), H.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(np.arange(0, N), H.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('plot_20200504_1120.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
