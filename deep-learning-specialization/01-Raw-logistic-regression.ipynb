{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data (images)\n",
    "# write the formula of sigmoid + logistic regression + gradient descent\n",
    "# define random weights + bias\n",
    "# write function to train (update weights and bias), and the parameters should be weights, bias,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# bank = pd.read_csv('data/Bank-data.csv')\n",
    "\n",
    "# # X = bank[['interest_rate', 'duration']]\n",
    "# X = bank[['duration']]\n",
    "# y = bank['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=3)\n",
    "\n",
    "# X_train_T = X_train.values.T\n",
    "# X_test_T = X_test.values.T\n",
    "\n",
    "# y_train = y_train.values.reshape((y_train.shape[0], 1))\n",
    "# y_test = y_test.values.reshape((y_test.shape[0], 1))\n",
    "\n",
    "# y_train_T = y_train.T\n",
    "# y_test_T = y_test.T\n",
    "\n",
    "# print(X_train_T.shape, X_test_T.shape, y_train_T.shape, y_test_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_utils import load_dataset\n",
    "\n",
    "X_train_T, y_train_T, X_test_T, y_test_T, classes = load_dataset()\n",
    "\n",
    "X_train_T = X_train_T.reshape(X_train_T.shape[0], -1).T\n",
    "X_test_T = X_test_T.reshape(X_test_T.shape[0], -1).T\n",
    "\n",
    "X_train_T = X_train_T / 255.\n",
    "X_test_T = X_test_T / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X, y)\n",
    "# List formulas\n",
    "# Loss function: -(y * log(y_hat) + (1 - y) * log(1 - y_hat))\n",
    "# Logistic function (sigmoid): 1 / (1 + e^(-z))\n",
    "# Use computer graph to compute gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(weights, bias, learning_rate, X, y, epochs=1):\n",
    "    m = len(X)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        A = sigmoid(np.dot(weights.T, X) + bias)\n",
    "\n",
    "        dz = A - y\n",
    "        dw = np.dot(X, dz.T) / m\n",
    "        db = np.sum(dz) / m\n",
    "        \n",
    "        weights = weights - learning_rate * dw\n",
    "        bias = bias - learning_rate * db\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, bias, X, y):\n",
    "    Z = np.dot(weights.T, X) + bias\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    correct = 0\n",
    "        \n",
    "    for i in range(len(A[0])):\n",
    "        a = A[0, i]\n",
    "        a = 1 if a > 0.5 else 0\n",
    "        y_i = y[0, i]\n",
    "        \n",
    "        if a == y_i:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / m * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1)\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(shape=(X_train_T.shape[0], 1))\n",
    "\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = linear_regression(weights, bias, 0.05, X_train_T, y_train_T, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(weights, bias, X_test_T, y_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.34449760765551"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(weights, bias, X_train_T, y_train_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
