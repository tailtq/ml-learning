{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "The values produced by features don't involve directly in output calculation process. (Không tham gia trực tiếp vào quá trình tính toán)\n",
    "\n",
    "How does decision tree pick features for itself?\n",
    "- **Question: How to build the shortest tree?**\n",
    "- Calculate the gain of each feature by using entropy cost function (calculate chaos of data)\n",
    "- Algorithms to build decision tree\n",
    "    - ID3\n",
    "    - C4.5\n",
    "    - Gini index\n",
    "\n",
    "__Entropy formula:__\n",
    "$$Entropy(S) = -p_1 * log_2(p_1) - p_2 * log_2(p_1) = -\\sum_{i=1}^{n} p_i * log_2(p_i)$$\n",
    "\n",
    "- Perfect classification: ---- | ++++. **Entropy = 0**\n",
    "- Worst classification: +-+- | -+-+ (50 - 50)... **Entropy = 1** (-(1/2) * log(-1/2) - (1/2) * log(-1/2))\n",
    "\n",
    "<!-- <img src=\"images/entropy-classification.png\" style=\"width: 25%; height: auto\"> -->\n",
    "<!-- <img src=\"images/entropy-formula.png\" style=\"width: 25%; height: auto\"> -->\n",
    "\n",
    "__Information gain (ID3):__\n",
    "$$Gain(S, A) = Entropy(S) - \\sum_{v \\in Values(A)}(\\frac{|S_V|}{|S|}) * Entropy(S_v) $$\n",
    "\n",
    "- S: Number of rows\n",
    "We will __choose a feature with the highest information gain__ to be a splitting attribute for node N. After choosing the feature, we will remove the rows having entropy of that value = 0 and drop the column.\n",
    "Ex: After choosing the weather feature, we can clear row having \"Rainy\" and \"Sunny\" weather, keep the \"cloudy\" for further operation, then drop \"weather\" column\n",
    "<!-- <img src=\"images/entropy-weather.png\" style=\"width: 25%; height: auto\"> -->\n",
    "\n",
    "__Gain Ratio (C4.5):__\n",
    "- Feature having many partitions: Should not be chosen as a node\n",
    "- Using C4.5 -> Solving many partitions problem that ID3 cannot solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/cdn-uploads/Decision_Tree-2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
