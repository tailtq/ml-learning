{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, activation='relu', input_shape=inputShape))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (128, 128, 3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print('[INFO] loading images...')\n",
    "imagePaths = sorted(list(paths.list_images('dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 805.63MB\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)\n",
    "print('[INFO] data matrix: {:.2f}MB'.format(data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                        shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From <ipython-input-7-fcee58ef8064>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 52 steps, validate on 420 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 36s 698ms/step - loss: 1.9802 - accuracy: 0.4721 - val_loss: 5.2901 - val_accuracy: 0.1524\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 1.6122 - accuracy: 0.5389 - val_loss: 2.5965 - val_accuracy: 0.2571\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 1.4805 - accuracy: 0.5474 - val_loss: 2.4092 - val_accuracy: 0.3095\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 1.2726 - accuracy: 0.6087 - val_loss: 1.4095 - val_accuracy: 0.4714\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 1.0584 - accuracy: 0.6671 - val_loss: 2.2764 - val_accuracy: 0.3548\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.9406 - accuracy: 0.6829 - val_loss: 1.5384 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.8657 - accuracy: 0.7145 - val_loss: 1.6171 - val_accuracy: 0.5048\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.7867 - accuracy: 0.7290 - val_loss: 1.4179 - val_accuracy: 0.5571\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.7851 - accuracy: 0.7326 - val_loss: 1.0849 - val_accuracy: 0.6429\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.7065 - accuracy: 0.7691 - val_loss: 0.9899 - val_accuracy: 0.6952\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.6574 - accuracy: 0.7710 - val_loss: 0.8431 - val_accuracy: 0.6929\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.5897 - accuracy: 0.8007 - val_loss: 0.7353 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.5767 - accuracy: 0.8038 - val_loss: 0.9121 - val_accuracy: 0.7548\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.5540 - accuracy: 0.8111 - val_loss: 0.7643 - val_accuracy: 0.7595\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 5s 88ms/step - loss: 0.5200 - accuracy: 0.8135 - val_loss: 0.6972 - val_accuracy: 0.7762\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.5040 - accuracy: 0.8232 - val_loss: 1.1489 - val_accuracy: 0.6500\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.4905 - accuracy: 0.8396 - val_loss: 0.8244 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.4673 - accuracy: 0.8317 - val_loss: 0.7761 - val_accuracy: 0.7833\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.4363 - accuracy: 0.8475 - val_loss: 0.6811 - val_accuracy: 0.7929\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.4130 - accuracy: 0.8518 - val_loss: 1.0316 - val_accuracy: 0.7357\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3709 - accuracy: 0.8682 - val_loss: 0.7250 - val_accuracy: 0.7714\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3726 - accuracy: 0.8702 - val_loss: 0.7429 - val_accuracy: 0.7905\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3709 - accuracy: 0.8694 - val_loss: 0.9334 - val_accuracy: 0.7548\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.3225 - accuracy: 0.8761 - val_loss: 0.7834 - val_accuracy: 0.7929\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.2916 - accuracy: 0.9004 - val_loss: 0.6023 - val_accuracy: 0.8262\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.2690 - accuracy: 0.8998 - val_loss: 0.6949 - val_accuracy: 0.8190\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3081 - accuracy: 0.8967 - val_loss: 0.8535 - val_accuracy: 0.7548\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3206 - accuracy: 0.8870 - val_loss: 0.7897 - val_accuracy: 0.7976\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.2394 - accuracy: 0.9064 - val_loss: 0.7167 - val_accuracy: 0.8095\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.2681 - accuracy: 0.9004 - val_loss: 1.0934 - val_accuracy: 0.7333\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 5s 87ms/step - loss: 0.2536 - accuracy: 0.9095 - val_loss: 0.8555 - val_accuracy: 0.8048\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 5s 88ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.7112 - val_accuracy: 0.8119\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.2105 - accuracy: 0.9241 - val_loss: 0.6676 - val_accuracy: 0.8214\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.2253 - accuracy: 0.9253 - val_loss: 0.8575 - val_accuracy: 0.7476\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.2642 - accuracy: 0.9093 - val_loss: 1.0300 - val_accuracy: 0.7762\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.2367 - accuracy: 0.9056 - val_loss: 0.8843 - val_accuracy: 0.7833\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1856 - accuracy: 0.9283 - val_loss: 0.6589 - val_accuracy: 0.8310\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.1990 - accuracy: 0.9301 - val_loss: 0.8604 - val_accuracy: 0.8071\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1563 - accuracy: 0.9484 - val_loss: 0.7433 - val_accuracy: 0.8286\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1516 - accuracy: 0.9520 - val_loss: 0.9513 - val_accuracy: 0.7690\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1815 - accuracy: 0.9380 - val_loss: 1.2999 - val_accuracy: 0.7214\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1974 - accuracy: 0.9313 - val_loss: 0.6538 - val_accuracy: 0.8548\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.1869 - accuracy: 0.9344 - val_loss: 0.7389 - val_accuracy: 0.8429\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1490 - accuracy: 0.9465 - val_loss: 0.8085 - val_accuracy: 0.8167\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.2046 - accuracy: 0.9289 - val_loss: 1.1129 - val_accuracy: 0.7619\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.2050 - accuracy: 0.9259 - val_loss: 0.6870 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1213 - accuracy: 0.9550 - val_loss: 0.6519 - val_accuracy: 0.8595\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1069 - accuracy: 0.9648 - val_loss: 0.5640 - val_accuracy: 0.8595\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 0.6435 - val_accuracy: 0.8429\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1144 - accuracy: 0.9581 - val_loss: 0.7267 - val_accuracy: 0.8524\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1466 - accuracy: 0.9447 - val_loss: 0.9337 - val_accuracy: 0.7762\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.1256 - accuracy: 0.9557 - val_loss: 0.6893 - val_accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1184 - accuracy: 0.9599 - val_loss: 0.7521 - val_accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1361 - accuracy: 0.9520 - val_loss: 0.7755 - val_accuracy: 0.8476\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1037 - accuracy: 0.9629 - val_loss: 0.8274 - val_accuracy: 0.8429\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0872 - accuracy: 0.9690 - val_loss: 0.6713 - val_accuracy: 0.8690\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.5914 - val_accuracy: 0.8643\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.1000 - accuracy: 0.9654 - val_loss: 1.2599 - val_accuracy: 0.7667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1165 - accuracy: 0.9569 - val_loss: 0.7443 - val_accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0941 - accuracy: 0.9654 - val_loss: 0.7985 - val_accuracy: 0.8262\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.1051 - accuracy: 0.9642 - val_loss: 0.7857 - val_accuracy: 0.8143\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0935 - accuracy: 0.9654 - val_loss: 0.7079 - val_accuracy: 0.8524\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0906 - accuracy: 0.9672 - val_loss: 0.7660 - val_accuracy: 0.8476\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0821 - accuracy: 0.9721 - val_loss: 0.8453 - val_accuracy: 0.8190\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.0905 - accuracy: 0.9635 - val_loss: 1.0885 - val_accuracy: 0.8048\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.1130 - accuracy: 0.9581 - val_loss: 1.0737 - val_accuracy: 0.7738\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.0817 - accuracy: 0.9757 - val_loss: 0.9772 - val_accuracy: 0.8167\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.1373 - accuracy: 0.9538 - val_loss: 0.9416 - val_accuracy: 0.8357\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.1528 - accuracy: 0.9563 - val_loss: 0.8597 - val_accuracy: 0.8452\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.1132 - accuracy: 0.9581 - val_loss: 0.7720 - val_accuracy: 0.8381\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1026 - accuracy: 0.9629 - val_loss: 0.8544 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1069 - accuracy: 0.9599 - val_loss: 1.1477 - val_accuracy: 0.7952\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1165 - accuracy: 0.9544 - val_loss: 0.9576 - val_accuracy: 0.8190\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0950 - accuracy: 0.9654 - val_loss: 0.8061 - val_accuracy: 0.8452\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0945 - accuracy: 0.9745 - val_loss: 0.7328 - val_accuracy: 0.8429\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0920 - accuracy: 0.9727 - val_loss: 0.7444 - val_accuracy: 0.8429\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0779 - accuracy: 0.9708 - val_loss: 0.8190 - val_accuracy: 0.8286\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 1.0448 - val_accuracy: 0.8310\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0969 - accuracy: 0.9672 - val_loss: 0.7222 - val_accuracy: 0.8714\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0893 - accuracy: 0.9684 - val_loss: 0.7762 - val_accuracy: 0.8524\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1021 - accuracy: 0.9733 - val_loss: 0.9168 - val_accuracy: 0.8310\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0662 - accuracy: 0.9781 - val_loss: 0.8707 - val_accuracy: 0.8405\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1022 - accuracy: 0.9654 - val_loss: 1.3982 - val_accuracy: 0.7881\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1059 - accuracy: 0.9642 - val_loss: 0.9400 - val_accuracy: 0.8214\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0996 - accuracy: 0.9617 - val_loss: 0.9676 - val_accuracy: 0.8405\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0818 - accuracy: 0.9727 - val_loss: 1.1460 - val_accuracy: 0.7976\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0770 - accuracy: 0.9793 - val_loss: 0.8713 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.7530 - val_accuracy: 0.8810\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0876 - accuracy: 0.9684 - val_loss: 0.8709 - val_accuracy: 0.8452\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 0.8335 - val_accuracy: 0.8429\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.0651 - accuracy: 0.9793 - val_loss: 0.8732 - val_accuracy: 0.8429\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.3071 - accuracy: 0.9052 - val_loss: 3.1621 - val_accuracy: 0.5833\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1917 - accuracy: 0.9338 - val_loss: 1.3829 - val_accuracy: 0.7595\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1589 - accuracy: 0.9514 - val_loss: 1.0670 - val_accuracy: 0.8048\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1229 - accuracy: 0.9587 - val_loss: 0.9504 - val_accuracy: 0.8310\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1045 - accuracy: 0.9696 - val_loss: 1.0155 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 0.0943 - accuracy: 0.9690 - val_loss: 0.9654 - val_accuracy: 0.8310\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 4s 85ms/step - loss: 0.0683 - accuracy: 0.9733 - val_loss: 0.7867 - val_accuracy: 0.8524\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 4s 84ms/step - loss: 0.1093 - accuracy: 0.9629 - val_loss: 0.9768 - val_accuracy: 0.8357\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 4s 83ms/step - loss: 0.1675 - accuracy: 0.9465 - val_loss: 1.1650 - val_accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] compiling model...')\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print('[INFO] training network...')\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "\n",
    "f = open('label.pickle', 'wb')\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, N), H.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, N), H.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(np.arange(0, N), H.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
